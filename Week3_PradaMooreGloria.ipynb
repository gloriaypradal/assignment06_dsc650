{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "matched-market",
   "metadata": {},
   "source": [
    "# Week3. Schemas\n",
    "\n",
    "## Gloria P Moore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prepared-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow as pa\n",
    "from pyarrow.json import read_json\n",
    "import pyarrow.parquet as pq\n",
    "import fastavro\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_jsonl_data():\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "        \n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "systematic-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = read_jsonl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "purple-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'airline': {'airline_id': 410,\n",
       "   'name': 'Aerocondor',\n",
       "   'alias': 'ANA All Nippon Airways',\n",
       "   'iata': '2B',\n",
       "   'icao': 'ARD',\n",
       "   'callsign': 'AEROCONDOR',\n",
       "   'country': 'Portugal',\n",
       "   'active': True},\n",
       "  'src_airport': {'airport_id': 2965,\n",
       "   'name': 'Sochi International Airport',\n",
       "   'city': 'Sochi',\n",
       "   'country': 'Russia',\n",
       "   'iata': 'AER',\n",
       "   'icao': 'URSS',\n",
       "   'latitude': 43.449902,\n",
       "   'longitude': 39.9566,\n",
       "   'altitude': 89,\n",
       "   'timezone': 3.0,\n",
       "   'dst': 'N',\n",
       "   'tz_id': 'Europe/Moscow',\n",
       "   'type': 'airport',\n",
       "   'source': 'OurAirports'},\n",
       "  'dst_airport': {'airport_id': 2990,\n",
       "   'name': 'Kazan International Airport',\n",
       "   'city': 'Kazan',\n",
       "   'country': 'Russia',\n",
       "   'iata': 'KZN',\n",
       "   'icao': 'UWKD',\n",
       "   'latitude': 55.606201171875,\n",
       "   'longitude': 49.278701782227,\n",
       "   'altitude': 411,\n",
       "   'timezone': 3.0,\n",
       "   'dst': 'N',\n",
       "   'tz_id': 'Europe/Moscow',\n",
       "   'type': 'airport',\n",
       "   'source': 'OurAirports'},\n",
       "  'codeshare': False,\n",
       "  'equipment': ['CR2']}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "going-freight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/results/validation-results.csv')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bearing-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    schema_path = schema_dir.joinpath('routes-schema.json')\n",
    "    validation_csv_path = results_dir.joinpath('validation-results.csv')\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    " \n",
    "    \n",
    "    with open(validation_csv_path, 'w') as f:    \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                jsonschema.validate(instance=record, schema=schema) \n",
    "                pass\n",
    "            except ValidationError as e:\n",
    "                print(\"ERROR!!\")\n",
    "                pass\n",
    "            \n",
    "\n",
    "validate_jsonl_data(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "induced-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = {\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"Route\",\n",
    "  \"namespace\": \"edu.bellevue.dsc650\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"airline\",\n",
    "      \"type\": {\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Airline\",\n",
    "        \"fields\": [\n",
    "          {\n",
    "            \"name\": \"airline_id\",\n",
    "            \"type\": \"int\",\n",
    "            \"default\": -1\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"name\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"alias\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"iata\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"icao\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"callsign\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"country\",\n",
    "            \"type\": \"string\",\n",
    "            \"default\": \"NONE\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"active\",\n",
    "            \"type\": \"boolean\",\n",
    "            \"default\": False\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"default\": \"NONE\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"src_airport\",\n",
    "      \"type\": [\n",
    "        {\n",
    "          \"type\": \"record\",\n",
    "          \"name\": \"Airport\",\n",
    "          \"fields\": [\n",
    "            {\n",
    "              \"name\": \"airport_id\",\n",
    "              \"type\": \"int\",\n",
    "              \"default\": -1\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"name\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"city\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"iata\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"icao\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"latitude\",\n",
    "              \"type\": \"double\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"longitude\",\n",
    "              \"type\": \"double\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"timezone\",\n",
    "              \"type\": \"double\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"dst\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"tz_id\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"type\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"source\",\n",
    "              \"type\": \"string\",\n",
    "              \"default\": \"NONE\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        \"null\"\n",
    "      ],\n",
    "      \"default\": \"NONE\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"dst_airport\",\n",
    "      \"type\": [\n",
    "        \"Airport\",\n",
    "        \"null\"\n",
    "      ],\n",
    "      \"default\": \"NONE\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"codeshare\",\n",
    "      \"type\": \"boolean\",\n",
    "      \"default\": False\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"stops\",\n",
    "      \"type\": \"int\",\n",
    "      \"default\": 0\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"equipment\",\n",
    "      \"type\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": \"string\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-afghanistan",
   "metadata": {},
   "source": [
    "# AVRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "wicked-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastavro import parse_schema\n",
    "from fastavro import writer\n",
    "\n",
    "parsed_schema = parse_schema(schema1)\n",
    "with open('routes.avsc', 'wb') as out:\n",
    "    writer(out, parsed_schema, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "welcome-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastavro import writer, reader, parse_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "valued-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "    \n",
    "    parsed_schema = parse_schema(schema1)\n",
    "    with open('routes.avro', 'wb') as out:\n",
    "        writer(out, parsed_schema, records[0:2])    \n",
    "        \n",
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "approved-cathedral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airline': {'airline_id': 410,\n",
       "  'name': 'Aerocondor',\n",
       "  'alias': 'ANA All Nippon Airways',\n",
       "  'iata': '2B',\n",
       "  'icao': 'ARD',\n",
       "  'callsign': 'AEROCONDOR',\n",
       "  'country': 'Portugal',\n",
       "  'active': True},\n",
       " 'src_airport': {'airport_id': 2966,\n",
       "  'name': 'Astrakhan Airport',\n",
       "  'city': 'Astrakhan',\n",
       "  'country': 'Russia',\n",
       "  'iata': 'ASF',\n",
       "  'icao': 'URWA',\n",
       "  'latitude': 46.2832984924,\n",
       "  'longitude': 48.0063018799,\n",
       "  'altitude': -65,\n",
       "  'timezone': 4.0,\n",
       "  'dst': 'N',\n",
       "  'tz_id': 'Europe/Samara',\n",
       "  'type': 'airport',\n",
       "  'source': 'OurAirports'},\n",
       " 'dst_airport': {'airport_id': 2990,\n",
       "  'name': 'Kazan International Airport',\n",
       "  'city': 'Kazan',\n",
       "  'country': 'Russia',\n",
       "  'iata': 'KZN',\n",
       "  'icao': 'UWKD',\n",
       "  'latitude': 55.606201171875,\n",
       "  'longitude': 49.278701782227,\n",
       "  'altitude': 411,\n",
       "  'timezone': 3.0,\n",
       "  'dst': 'N',\n",
       "  'tz_id': 'Europe/Moscow',\n",
       "  'type': 'airport',\n",
       "  'source': 'OurAirports'},\n",
       " 'codeshare': False,\n",
       " 'equipment': ['CR2']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-glenn",
   "metadata": {},
   "source": [
    "# PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "living-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parquet_dataset():\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            pass\n",
    "            df = pd.DataFrame(records)\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            pq.write_table(table,'routes.parquet')\n",
    "\n",
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-columbus",
   "metadata": {},
   "source": [
    "# Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eligible-petite",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'routes_pb2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0c3e0b4acae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'routes_pb2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mroutes_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_airport_to_proto_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'routes_pb2'"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        airline = _airline_to_proto_obj(record.get('airline', {}))\n",
    "        if airline:\n",
    "            route.airline.CopyFrom(airline)\n",
    "        src_airport = _airport_to_proto_obj(record.get('src_airport', {}))\n",
    "        if src_airport:\n",
    "            route.src_airport.CopyFrom(src_airport)\n",
    "        dst_airport = _airport_to_proto_obj(record.get('dst_airport', {}))\n",
    "        if dst_airport:\n",
    "            route.dst_airport.CopyFrom(dst_airport)\n",
    "            \n",
    "        if record.get('codeshare'):\n",
    "            route.codeshare = record.get('codeshare')\n",
    "        else:\n",
    "            route.codeshare = False\n",
    "            \n",
    "        if record.get('stops'):\n",
    "            route.stops = record.get('stops')\n",
    "        \n",
    "        equipment = record.get('equipment')\n",
    "        \n",
    "        if len(equipment) > 1:\n",
    "            for i, v in enumerate(equipment):\n",
    "                route.equipment.append(v)\n",
    "        else:\n",
    "            equipment = record.get('equipment')\n",
    "\n",
    "        routes.route.append(route)\n",
    "        \n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "    \n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "    with open(compressed_path, 'wb') as f:\n",
    "        f.write(snappy.compress(routes.SerializeToString()))\n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-cuisine",
   "metadata": {},
   "source": [
    "# OUTPUT SIZES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-syndrome",
   "metadata": {},
   "source": [
    "I don't know how to make this part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-protocol",
   "metadata": {},
   "source": [
    "# 3.2 gEOhASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eleven-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                hash1 = pygeohash.encode(latitude,longitude)\n",
    "                record['geohash']=hash1\n",
    "                hashes.append(hash1)\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))\n",
    "            \n",
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "modified-reference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eppley Airfield\n"
     ]
    }
   ],
   "source": [
    "def airport_search(latitude, longitude):\n",
    "    h = pygeohash.encode(latitude,longitude)\n",
    "    dist = 0\n",
    "    name = ''\n",
    "    for i,record in enumerate(records):\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            lat = src_airport.get('latitude')\n",
    "            long = src_airport.get('longitude')\n",
    "            a_name = src_airport.get('name')\n",
    "            if lat and long:\n",
    "                h2 = pygeohash.encode(lat,long)\n",
    "                \n",
    "                dist_n = pygeohash.geohash_approximate_distance(h,h2)\n",
    "                if i==0:\n",
    "                    dist = dist_n\n",
    "                else:\n",
    "                    if dist > dist_n:\n",
    "                        dist = dist_n\n",
    "                        name = a_name\n",
    "    print(name)\n",
    "    pass\n",
    "    \n",
    "airport_search(41.1499988, -95.91779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "balanced-budapest",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-244aa7266b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "collectible-brass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbzip\n",
      "  Downloading nbzip-0.1.0-py3-none-any.whl (4.5 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from nbzip) (6.2.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (5.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (4.7.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (0.9.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (0.9.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (20.1.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (5.5.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (6.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (6.0.7)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (22.0.3)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (6.1.12)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /opt/conda/lib/python3.8/site-packages (from notebook->nbzip) (5.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=5.3.4->notebook->nbzip) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=5.3.4->notebook->nbzip) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->nbzip) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->nbzip) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->nbzip) (2.20)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel->notebook->nbzip) (7.21.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (0.18.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (3.0.17)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (4.4.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (2.8.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->notebook->nbzip) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook->nbzip) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->nbzip) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook->nbzip) (1.1.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.5.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (1.4.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook->nbzip) (0.1.2)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->nbzip) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->nbzip) (1.4.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat->notebook->nbzip) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->nbzip) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->nbzip) (0.17.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook->nbzip) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook->nbzip) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook->nbzip) (2.4.7)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 447 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: toml, py, pluggy, iniconfig, pytest, nbzip\n",
      "Successfully installed iniconfig-1.1.1 nbzip-0.1.0 pluggy-0.13.1 py-1.10.0 pytest-6.2.3 toml-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-float",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "divine-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -czf archive.tar.gz data/enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-visitor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
